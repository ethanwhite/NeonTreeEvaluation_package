% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/summary_statistics.R
\name{grand_summary}
\alias{grand_summary}
\title{Summary statistics for evaluated crowns}
\usage{
grand_summary(results, threshold = 0.5)
}
\arguments{
\item{results}{A data frame of matched predictions and ground truth returned from \code{evaluate_plot}}

\item{threshold}{Float. Intersection-over-union threshold to consider a prediction a true positive.}

\item{by_site}{Logical. Should average recall and precision be calculated for each geographic site separately? Defaults to FALSE, such that a single summary is returned for all sites.}

\item{calc_plot_level}{Calculate plot-level statistic comparing the total predictions to the total crowns. This only makes sense for the image-annotated crowns, and not the field-annotated crowns.}
}
\value{
A names list of overall mean precision and recall, by site, and plot level summary
}
\description{
\code{summary_statistics} returns a standardized summary of plot evaluations. The mean recall and precision can be calculated either for the entire dataset, or for each of the 22 geographic sites.
}
