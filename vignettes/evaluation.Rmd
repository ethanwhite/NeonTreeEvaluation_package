---
title: "Benchmark Evaluation"
author: "Ben Weinstein"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{evaluation}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

# Submission Format

The format of the submission is as follows

* A csv file
* 5 columns: Plot Name, xmin, ymin, xmax, ymax

Each row contains information for one predicted bounding box.

The plot column should be named the same as the files in the dataset (e.g. SJER_021) without file extensions.

```{r}
library(dplyr)
library(NeonTreeEvaluation)
library(reshape2)
library(ggplot2)
library(lidR)

#Load sample submission
data("submission")
```

# Evaluation

For each plot compute the precision and recall based on intersection-over-union of 0.5 between the ground truth bounding boxes and the predicted boxes. The loop through all matching plot_names and produce evaluation scores

```{r,eval=FALSE}
results<-evaluate_image_crowns(submission = submission,project_boxes = T, show=F, summarize = T)
```

There are several options that need to be considered. see ?evaluate_benchmark. For example, `project_boxes` asks whether the predicted boxes should be projected in universal-transverse mercator projection (UTM) from the image coordinate system. For example,

```{r}
head(submission)
```

These boxes are in the image coordinate system. The xmin of the first box is 299.53 (pixels) from the top left. The images are projected and have units in meters. Therefore we need to transform the image coordinates to the geographic coordinates for the boxes to overlap. 

For the sake of computation in this small vignette, let's select just 5 images.

```{r,include=FALSE}
results<-submission %>% filter(plot_name %in% sample(plot_name,5)) %>% evaluate_image_crowns(.,project_boxes = T,show=T,summarize = T)
```

### Overall Performance
```{r}
results[["overall"]]
```

### By Site

Precision and recall for each NEON site.

```{r}
df<-melt(results[["by_site"]])
ggplot(df,aes(y=value,x=variable)) + geom_boxplot()
```

### Plot Level

Number of predicted trees versus number of image-annotated trees for each plot. A good model will fall on the 1:1 line.

```{r}
df<-results[["plot_level"]]
ggplot(df,aes(y=submission,x=ground_truth)) + geom_point() + geom_abline(linetype="dashed") + coord_equal()
```

# Worked example

Using the tree deliniation tools in the liDR package, let's produce a prediction and test it against the benchmark. See the data vignette for more information.

```{r}
#Load RGB information
rgb<-get_data("SJER_052","rgb")
img<-stack(rgb)

#Load annotations
xml<-get_data("SJER_052","annotations")
annotations<-xml_parse(xml)
ground_truth <- boxes_to_spatial_polygons(annotations,img)

#Load LiDAR data
point_cloud_path<-get_data("SJER_052","lidar")
point_cloud<-readLAS(point_cloud_path)
```

## Compute Height Model

The liDR R package provides some nice tools for look at the point cloud as a raster grid.
```{r,fig.height=5,fig.width=7}
chm <- lidR::grid_canopy(point_cloud, res = 0.5, lidR::pitfree(c(0,2,5,10,15), c(0, 1.5)))
plot(chm)
```

## Predict trees

Using the lidR R package, we can perform individual tree prediction. Below we demonstrate how to predict trees and format the data for evaluation against the benchmark annotations. 

```{r}
ttops <- tree_detection(chm, lmf(4, 2))
point_cloud   <- lastrees(point_cloud, silva2016(chm, ttops,max_cr_factor = 0.5,exclusion = 0.3))
```

The lidR package adds predicted labels into the treeID column
```{r}
plot(point_cloud,color="treeID")
```

```{r}
predictions<-tree_hulls(point_cloud,"bbox")
plotRGB(img)
plot(predictions,add=T,border="red")
```

## Evaluate against benchmark annotations

Now that we have ground truth and prediction polygon objects, what is the precision and recall for bounding boxes with intersection-over-union of greather than 0.5

```{r}
predictions$crown_id<-predictions$treeID
compute_precision_recall(ground_truth,predictions,threshold = 0.5)
```
